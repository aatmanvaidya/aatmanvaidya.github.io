<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>research | Aatman Vaidya</title> <meta name="author" content="Aatman Vaidya"> <meta name="description" content="List of published and ongoing research work"> <meta name="keywords" content="aatman, aatman vaidya"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://aatmanvaidya.github.io/research/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Aatman¬†</span>Vaidya</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">research<span class="sr-only">(current)</span></a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/cv.pdf"> cv </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">research</h1> <p class="post-description">List of published and ongoing research work</p> </header> <article> <div class="publications"> <h2 class="year">ongoing</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="vaidya2025quant" class="col-sm-8"> <div class="title">Quantifying the Illicit Ecosystem of Betting Apps in India</div> <div class="author"> <em><b>Aatman Vaidya</b></em>,¬†and¬†Kiran Garimella</div> <div class="periodical"> 2025 </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="year">published</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ArXiv</abbr></div> <div id="vaidya2025modellingspreadtoxicityexploring" class="col-sm-8"> <div class="title">Modelling the Spread of Toxicity and Exploring its Mitigation on Online Social Networks</div> <div class="author"> <em><b>Aatman Vaidya</b></em>,¬†Harsh Bhagat,¬†<a href="https://research.ibm.com/people/seema-nagar" rel="external nofollow noopener" target="_blank">Seema Nagar</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Amit A Nanavati' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2511.20546" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Web</a> <a href="/assets/papers/mode_toxicity.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Hate speech on online platforms has been credibly linked to multiple instances of real world violence. This calls for an urgent need to understand how toxic content spreads and how it might be mitigated on online social networks, and expectedly has been the topic of extensive research in recent times. Prior work has largely modelled hate through epidemic or spread activation based diffusion models, in which the users are often divided into two categories, hateful or not. In this work, users are treated as transformers of toxicity, based on how they respond to incoming toxicity. Compared with the incoming toxicity, users amplify, attenuate, or replicate (effectively, transform) the toxicity and send it forward. We do a temporal analysis of toxicity on Twitter, Koo and Gab and find that (a) toxicity is not conserved in the network; (b) only a subset of users change behaviour over time; and (c) there is no evidence of homophily among behaviour-changing users. In our model, each user transforms incoming toxicity by applying a "shift" to it prior to sending it forward. Based on this, we develop a network model of toxicity spread that incorporates time-varying behaviour of users. We find that the "shift" applied by a user is dependent on the input toxicity and the category. Based on this finding, we propose an intervention strategy for toxicity reduction. This is simulated by deploying peace-bots. Through experiments on both real-world and synthetic networks, we demonstrate that peace-bot interventions can reduce toxicity, though their effectiveness depends on network structure and placement strategy.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ArXiv</abbr></div> <div id="vaidya2025analysis" class="col-sm-8"> <div class="title">Analysis of Indic Language Capabilities in LLMs</div> <div class="author"> <em><b>Aatman Vaidya</b></em>,¬†<a href="https://tarunima.com/" rel="external nofollow noopener" target="_blank">Tarunima Prabhakar</a>,¬†<a href="https://github.com/dennyabrain" rel="external nofollow noopener" target="_blank">Denny George</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Swair Shah' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em></em> 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2501.13912" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Web</a> <a href="/assets/papers/eval_indic_llms.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This report evaluates the performance of text-in text-out Large Language Models (LLMs) to understand and generate Indic languages. This evaluation is used to identify and prioritize Indic languages suited for inclusion in safety benchmarks. We conduct this study by reviewing existing evaluation studies and datasets; and a set of twenty-eight LLMs that support Indic languages. We analyze the LLMs on the basis of the training data, license for model and data, type of access and model developers. We also compare Indic language performance across evaluation datasets and find that significant performance disparities in performance across Indic languages. Hindi is the most widely represented language in models. While model performance roughly correlates with number of speakers for the top five languages, the assessment after that varies.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NAACL 2024</abbr></div> <div id="arora2023uli" class="col-sm-8"> <div class="title">The Uli Dataset: An Exercise in Experience Led Annotation of oGBV</div> <div class="author"> Arnav Arora,¬†Maha Jinadoss,¬†Cheshta Arora, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Denny George, Brindaalakshmi, ...., Aatman Vaidya, Tarunima Prabhakar' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="award" style="color: #B51250;">üèÜ Outstanding Paper Award</div> <div class="periodical"> <em>In The 8th Workshop on Online Abuse and Harms at Annual Conference of the North American Chapter of the Association for Computational Linguistics</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://aclanthology.org/2024.woah-1.16/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Web</a> <a href="/assets/papers/ogbv_dataset.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/tattle-made/uli_dataset" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Dataset</a> <a href="https://uli.tattle.co.in/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>Online gender-based violence has grown concomitantly with the adoption of the internet and social media. Its effects are worse in the Global majority where many users use social media in languages other than English. The scale and volume of conversations on the internet have necessitated the need for automated detection of hate speech and, more specifically, gendered abuse. There is, however, a lack of language-specific and contextual data to build such automated tools. In this paper, we present a dataset on gendered abuse in three languages- Hindi, Tamil and Indian English. The dataset comprises of tweets annotated along three questions pertaining to the experience of gender abuse, by experts who identify as women or a member of the LGBTQIA+ community in South Asia. Through this dataset, we demonstrate a participatory approach to creating datasets that drive AI systems.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CODS-COMAD</abbr></div> <div id="vaidya2024analysing" class="col-sm-8"> <div class="title">Analysing the Spread of Toxicity on Twitter</div> <div class="author"> <em><b>Aatman Vaidya</b></em>,¬†<a href="https://research.ibm.com/people/seema-nagar" rel="external nofollow noopener" target="_blank">Seema Nagar</a>,¬†and¬†<a href="https://ahduni.edu.in/academics/schools-centres/school-of-engineering-and-applied-science/people-1/amit-a-nanavati/" rel="external nofollow noopener" target="_blank">Amit A Nanavati</a> </div> <div class="periodical"> <em>In Proceedings of the 7th Joint International Conference on Data Science &amp; Management of Data (11th ACM IKDD CODS and 29th COMAD)</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://dl.acm.org/doi/10.1145/3632410.3632436" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Web</a> </div> <div class="abstract hidden"> <p>The spread of hate speech on social media platforms has become a rising concern in recent years. Understanding the spread of hate is crucial for mitigating its harmful effects and fostering a healthier online environment. In this paper, we propose a new model to capture the evolution of toxicity in a network ‚Äì if a tweet with a certain toxicity (hatefulness) is posted, how much toxic a social network will become after a given number of rounds. We compute a toxicity score for each tweet, indicating the extent of the hatefulness of that tweet. Toxicity spread has not been adequately addressed in the existing literature. The two popular paradigms for modelling information spread, namely the Susceptible-Infected-Recovered (SIR) and its variants, as well as the spreading-activation models (SPA), are not suitable for modelling toxicity spread. The first paradigm employs a threshold and categorizes tweets as either toxic or non-toxic, while the second paradigm treats hate as energy and applies energy-conversion principles to model its propagation. Through analysis of a Twitter dataset consisting of 19.58 million tweets, we observe that the total toxicity, as well as the average toxicity of original tweets and retweets in the network, does not remain constant but rather increases over time. In this paper, we propose a new method for toxicity spread. First, we categorize users into three distinct groups: Amplifiers, Attenuators, and Copycats. These categories are assigned based on the exchange of toxicity by a user, with Amplifiers sending out more toxicity than they receive, Attenuators experiencing a higher influx of toxicity compared to what they generate, and Copycats simply mirroring the hate they receive. We perform extensive experimentation on Barab√°si‚ÄìAlbert (BA) graphs, as well as subgraphs extracted from the Twitter dataset. Our model is able to replicate the patterns of toxicity.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICON 2023</abbr></div> <div id="vaidya2024overview" class="col-sm-8"> <div class="title">Overview of the 2023 ICON Shared Task on Gendered Abuse Detection in Indic Languages</div> <div class="author"> <em><b>Aatman Vaidya</b></em>,¬†Arnav Arora,¬†<a href="https://www.unsw.edu.au/staff/aditya-joshi" rel="external nofollow noopener" target="_blank">Aditya Joshi</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Tarunima Prabhakar' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>The 20th International Conference on Natural Language Processing</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2401.03677" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Web</a> <a href="https://sites.google.com/view/icon2023-tattle-sharedtask/home" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>This paper reports the findings of the ICON 2023 on Gendered Abuse Detection in Indic Languages. The shared task deals with the detection of gendered abuse in online text. The shared task was conducted as a part of ICON 2023, based on a novel dataset in Hindi, Tamil and the Indian dialect of English. The participants were given three subtasks with the train dataset consisting of approximately 6500 posts sourced from Twitter. For the test set, approximately 1200 posts were provided. The shared task received a total of 9 registrations. The best F-1 scores are 0.616 for subtask 1, 0.572 for subtask 2 and, 0.616 and 0.582 for subtask 3. The paper contains examples of hateful content owing to its topic.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CoGMI 2023</abbr></div> <div id="vaidya2023forecasting" class="col-sm-8"> <div class="title">Forecasting the Spread of Toxicity on Twitter</div> <div class="author"> <em><b>Aatman Vaidya</b></em>,¬†<a href="https://research.ibm.com/people/seema-nagar" rel="external nofollow noopener" target="_blank">Seema Nagar</a>,¬†and¬†<a href="https://ahduni.edu.in/academics/schools-centres/school-of-engineering-and-applied-science/people-1/amit-a-nanavati/" rel="external nofollow noopener" target="_blank">Amit A Nanavati</a> </div> <div class="periodical"> <em>In IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI)</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/document/10431536" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Web</a> </div> <div class="abstract hidden"> <p>In this paper, we explore the question of whether it is possible to forecast the spread of hate on Twitter. Unlike most prior work which models the spread of Twitter over a network with the goal of predicting the future ‚Äústate" of a user (typically, as being "hateful" or not), here we are interested in how "hateful" (or toxic) the network as a whole becomes. We pose toxicity spread as a forecasting problem, and use ARIMA to find out whether the spread is forecastable. We find that toxicity spread is indeed forecasted by ARIMA. Given that it is forecastable, we ask two follow-up questions: (a) How well can we forecast it? and (b) What role, if any, does the structure of the retweet network play in forecasting? In order to answer these questions, we employ several techniques including Spatio-Temporal Graph Convolution Network (STGCN) and several variants of transformers. To determine the role that structure might play, we re-purpose the dataset in three ways: the network as a whole (the structure is ignored), communities interconnected with each other, and neighbourhoods of a set of individuals. Experiments with the network as a whole informs us how well we can forecast hate spread at a global level, while the latter experiments tell us whether and how network effects affect the forecasting. In an effort to tease out the effect of the network, we use two distinct techniques: STGCN, which requires the explicit connections in the form of a graph as input; and Transformers, where no explicit graph is given as input. Instead, we pose it as a multivariate analysis problem. We find that the PatchTST transformer performs the best at all levels. STGCN performs better than ARIMA suggesting that network structure matters. Somewhat interestingly, STGCN does not perform as well as PatchTST, suggesting that (a) PatchTST is able to implicitly learn the associations (flow of influence), and (b) the presence of explicit connections may not always imply influence.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> ¬© Copyright 2026 Aatman Vaidya. Design inspired by the <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: January 18, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>